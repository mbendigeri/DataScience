{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Boston data in the Tensorflow is a clean dataset and does not have any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==0.2.2\n",
      "alabaster==0.7.9\n",
      "anaconda-client==1.6.0\n",
      "anaconda-navigator==1.5\n",
      "anaconda-project==0.4.1\n",
      "appdirs==1.4.3\n",
      "astor==0.7.1\n",
      "astroid==1.4.9\n",
      "astropy==1.3\n",
      "Babel==2.3.4\n",
      "backports.shutil-get-terminal-size==1.0.0\n",
      "beautifulsoup4==4.5.3\n",
      "bitarray==0.8.1\n",
      "blaze==0.10.1\n",
      "bokeh==0.12.4\n",
      "boto==2.45.0\n",
      "Bottleneck==1.2.0\n",
      "cffi==1.9.1\n",
      "chardet==2.3.0\n",
      "chest==0.2.3\n",
      "click==6.7\n",
      "cloudpickle==0.2.2\n",
      "clyent==1.2.2\n",
      "colorama==0.3.7\n",
      "comtypes==1.1.2\n",
      "conda==4.5.6\n",
      "configobj==5.0.6\n",
      "contextlib2==0.5.4\n",
      "cryptography==1.7.1\n",
      "cycler==0.10.0\n",
      "Cython==0.25.2\n",
      "cytoolz==0.8.2\n",
      "dask==0.13.0\n",
      "datashape==0.5.4\n",
      "decorator==4.0.11\n",
      "dill==0.2.5\n",
      "docutils==0.13.1\n",
      "et-xmlfile==1.0.1\n",
      "fastcache==1.0.2\n",
      "Flask==0.12\n",
      "Flask-Cors==3.0.2\n",
      "future==0.16.0\n",
      "gast==0.2.0\n",
      "gevent==1.2.1\n",
      "greenlet==0.4.11\n",
      "grpcio==1.13.0\n",
      "h5py==2.6.0\n",
      "HeapDict==1.0.0\n",
      "idna==2.2\n",
      "imagesize==0.7.1\n",
      "ipykernel==4.5.2\n",
      "ipython==5.1.0\n",
      "ipython-genutils==0.1.0\n",
      "ipywidgets==5.2.2\n",
      "isort==4.2.5\n",
      "itsdangerous==0.24\n",
      "jdcal==1.3\n",
      "jedi==0.9.0\n",
      "Jinja2==2.9.4\n",
      "jsonschema==2.5.1\n",
      "jupyter==1.0.0\n",
      "jupyter-client==4.4.0\n",
      "jupyter-console==5.0.0\n",
      "jupyter-core==4.2.1\n",
      "lazy-object-proxy==1.2.2\n",
      "llvmlite==0.15.0\n",
      "locket==0.2.0\n",
      "lxml==3.7.2\n",
      "Markdown==2.6.11\n",
      "MarkupSafe==0.23\n",
      "matplotlib==2.0.0\n",
      "menuinst==1.4.4\n",
      "missingno==0.4.1\n",
      "mistune==0.7.3\n",
      "mpmath==0.19\n",
      "multipledispatch==0.4.9\n",
      "nbconvert==4.2.0\n",
      "nbformat==4.2.0\n",
      "networkx==1.11\n",
      "nltk==3.2.2\n",
      "nose==1.3.7\n",
      "notebook==4.3.1\n",
      "numba==0.30.1\n",
      "numexpr==2.6.1\n",
      "numpy==1.14.5\n",
      "numpydoc==0.6.0\n",
      "odo==0.5.0\n",
      "openpyxl==2.4.1\n",
      "packaging==17.1\n",
      "pandas==0.19.2\n",
      "pandas-profiling==1.4.1\n",
      "partd==0.3.7\n",
      "path.py==0.0.0\n",
      "pathlib2==2.2.0\n",
      "patsy==0.4.1\n",
      "pep8==1.7.0\n",
      "pickleshare==0.7.4\n",
      "Pillow==4.0.0\n",
      "ply==3.9\n",
      "prompt-toolkit==1.0.9\n",
      "protobuf==3.6.0\n",
      "psutil==5.0.1\n",
      "py==1.4.32\n",
      "pyarrow==0.7.1\n",
      "pyasn1==0.1.9\n",
      "pycosat==0.6.3\n",
      "pycparser==2.17\n",
      "pycrypto==2.6.1\n",
      "pycurl==7.43.0\n",
      "pyflakes==1.5.0\n",
      "Pygments==2.1.3\n",
      "pylint==1.6.4\n",
      "pyOpenSSL==16.2.0\n",
      "pyparsing==2.1.4\n",
      "pytest==3.0.5\n",
      "python-dateutil==2.6.0\n",
      "pytz==2016.10\n",
      "pywin32==220\n",
      "PyYAML==3.12\n",
      "pyzmq==16.0.2\n",
      "QtAwesome==0.4.3\n",
      "qtconsole==4.2.1\n",
      "QtPy==1.2.1\n",
      "quilt==2.9.6\n",
      "requests==2.12.4\n",
      "rope-py3k==0.9.4.post1\n",
      "scikit-image==0.12.3\n",
      "scikit-learn==0.18.1\n",
      "scipy==0.18.1\n",
      "seaborn==0.7.1\n",
      "simplegeneric==0.8.1\n",
      "singledispatch==3.4.0.3\n",
      "six==1.10.0\n",
      "snowballstemmer==1.2.1\n",
      "sockjs-tornado==1.0.3\n",
      "sphinx==1.5.1\n",
      "spyder==3.1.2\n",
      "SQLAlchemy==1.1.5\n",
      "statsmodels==0.9.0\n",
      "sympy==1.0\n",
      "tables==3.2.2\n",
      "tensorboard==1.9.0\n",
      "tensorflow==1.9.0\n",
      "termcolor==1.1.0\n",
      "toolz==0.8.2\n",
      "tornado==4.4.2\n",
      "tqdm==4.23.4\n",
      "traitlets==4.3.1\n",
      "unicodecsv==0.14.1\n",
      "wcwidth==0.1.7\n",
      "Werkzeug==0.11.15\n",
      "widgetsnbextension==1.2.6\n",
      "win-unicode-console==0.5\n",
      "wrapt==1.10.8\n",
      "xlrd==1.0.0\n",
      "XlsxWriter==0.9.6\n",
      "xlwings==0.10.2\n",
      "xlwt==1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.learn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-1342cabbc2bb>:2: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data.\n",
      "WARNING:tensorflow:From D:\\Mallikarjun\\UPXAcademylearning\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\__init__.py:80: load_boston (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use scikits.learn.datasets.\n",
      "WARNING:tensorflow:From D:\\Mallikarjun\\UPXAcademylearning\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:129: load_csv_with_header (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data instead.\n"
     ]
    }
   ],
   "source": [
    "#load_dataset is depreciated\n",
    "boston=datasets.load_dataset('boston')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_features or columns of the data set\n",
    "features=np.array(boston.data)\n",
    "# Actual output\n",
    "prices=np.array(boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prices=np.reshape(prices,(prices.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features shape (506, 13)\n",
      "Actual prices shape (506, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('Input features shape',features.shape)\n",
    "print ('Actual prices shape',prices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the input place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#input placeholder for the input features , None refers to any number of rows\n",
    "x=tf.placeholder(shape=[None,features.shape[1]],dtype=tf.float32,name='x-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#placeholder for the actual prices \n",
    "y_=tf.placeholder(shape=[None,prices.shape[1]],dtype=tf.float32,name='y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize the features using x min max method\n",
    "x_n=tf.nn.l2_normalize(x,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Wieghts and Bais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#variable for the wieghts \n",
    "w=tf.Variable(tf.zeros(shape=[features.shape[1],1]),name='Weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#variable for the bios \n",
    "b=tf.Variable(tf.zeros(shape=[1]),name='Bais')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "##### Make sure the data is normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y=xw+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of x is (?, 13)  and of that w  is (13, 1)\n"
     ]
    }
   ],
   "source": [
    "#The tf.matmul() op requires that both of its inputs are matrices (i.e. 2-D tensors)*, \n",
    "#and doesn't perform any automatic conversion. \n",
    "# check the dimnension of the x and w\n",
    "print ('The dimension of x is',x.shape,' and of that w  is',w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=tf.add(tf.matmul(x_n,w),b,name='output') # changed from x to x_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I tried to print the output of matrixx multiplication. The below is the error\n",
    "### You must feed a value for placeholder tensor 'x-input_1' with dtype float and shape [?,13]\n",
    "#with tf.Session() as sess:\n",
    " #   print(sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss(Cost function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Mean squared error\n",
    "# (The predicted - the actual)^2\n",
    "loss=tf.reduce_mean(tf.square(y-y_),name='Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Gradient Descent Optimizer to minimize loss\n",
    "#learn_rate\n",
    "learn_rate=0.3 # first value .03, second 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_op=tf.train.GradientDescentOptimizer(learn_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log the training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_loss=tf.summary.scalar('train_loss',loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_dir='/tmp/boston/v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss at  0  is  592.1469\n",
      "The loss at  100  is  72.251595\n",
      "The loss at  200  is  67.80704\n",
      "The loss at  300  is  65.681366\n",
      "The loss at  400  is  64.617775\n",
      "The loss at  500  is  64.04199\n",
      "The loss at  600  is  63.69156\n",
      "The loss at  700  is  63.44648\n",
      "The loss at  800  is  63.25185\n",
      "The loss at  900  is  63.082523\n"
     ]
    }
   ],
   "source": [
    "# start the tensorlfow session\n",
    "with tf.Session() as sess:\n",
    "    #intialize the variables before we start\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #Displaying of the data\n",
    "    training_epochs=1000\n",
    "    \n",
    "    #logging and saving the graph\n",
    "    saver=tf.train.Saver()\n",
    "    writer=tf.summary.FileWriter(log_dir,graph=tf.get_default_graph())\n",
    "    \n",
    "    for i in range(training_epochs):\n",
    "        #calculate the train_op and loss\n",
    "        train_model,train_loss,log_loss=sess.run([train_op,loss,training_loss],\n",
    "                                                 #execute the train_op (GradientDescentOptimizer) and loss\n",
    "                              feed_dict=({x:features,#data for input features\n",
    "                                        y_:prices}))# actual prices data\n",
    "                \n",
    "        writer.add_summary(log_loss,i)\n",
    "            #print i after every 10 iterations\n",
    "        if i%100==0:\n",
    "            print ('The loss at ',i,' is ',train_loss)\n",
    "    \n",
    "    #saave the graph\n",
    "    saver.save(sess,log_dir + '/' + 'Boston.ckpt')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### how to view in Tensor board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
